{"cells":[{"cell_type":"markdown","metadata":{"id":"3-vxqQd-9haB"},"source":["# Mental Health Sentiment Chatbot Application"]},{"cell_type":"markdown","metadata":{"id":"T5j89O859haD"},"source":["## Installing libraries, dependencies, and data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1721783558470,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"bH9X5lpJ9haE"},"outputs":[],"source":["# Import the required libraries and dependencies\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","\n","from dotenv import load_dotenv\n","import os\n","from langchain_openai import ChatOpenAI\n","from langchain import PromptTemplate\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.chains import LLMChain\n","\n","# Set the column width to view the statments.\n","pd.set_option('max_colwidth', 200)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1721783559371,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"5LBr7TwS9haH","outputId":"9c273ded-94d2-453f-8ba2-85b8d7786d19"},"outputs":[],"source":["# Load the dataset.\n","df = pd.read_csv(\"Combined Data.csv\", index_col=\"Unnamed: 0\")\n","# Display a sample of the dataset. \n","df.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"HpUSyf9d9haJ"},"source":["## Data Cleanup and Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721783559371,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"bhNwChvA9haJ"},"outputs":[],"source":["# Check for missing values. \n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Null values in the statement column\n","df['statement'].notnull().value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Drop null values\n","df = df.dropna()\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the number of different statuses in the status column:\n","df['status'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Turning the statement column to a list.\n","statements = df['statement'].to_list()\n","statements"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using the analyzer to determine the sentiment of each statement.\n","sentiment = []\n","score = []\n","analyzer = SentimentIntensityAnalyzer()\n","for statement in statements:\n","    statement_sentiment = analyzer.polarity_scores(statement)\n","    if statement_sentiment['compound'] >= 0.05:\n","        sentiment.append(\"Positive\")\n"," \n","    elif statement_sentiment['compound'] <= - 0.05:\n","        sentiment.append(\"Negative\")\n"," \n","    else:\n","        sentiment.append(\"Neutral\")\n","    score.append(statement_sentiment['compound'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating sentiment and score columns.\n","df['sentiment'] = sentiment\n","df['score'] = score\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Displaying a sample of the new DataFrame.\n","df.sample(10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the number of different results in the sentiment column:\n","df['sentiment'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set the features variable.\n","X = df['statement']\n","# Set the target variables.\n","y_status = df['status']\n","y_sentiment = df['sentiment']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split data into training and testing for status\n","X_status_train, X_status_test, y_status_train, y_stauts_test = train_test_split(X, y_status, test_size=0.30, random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split data into training and testing for sentiment\n","X_sentiment_train, X_sentiment_test, y_sentiment_train, y_sentiment_test = train_test_split(X, y_sentiment, test_size=0.30, random_state=1)"]},{"cell_type":"markdown","metadata":{"id":"R-5gfm-n9haK"},"source":["## ML Model"]},{"cell_type":"markdown","metadata":{},"source":["Title: y_status_train"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721783559372,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"wiFAyohp9haK"},"outputs":[],"source":["status_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(stop_words=None)),\n","    ('classifier', LinearSVC())\n","])\n","\n","status_pipeline.fit(X_status_train, y_status_train)\n","\n","# Print the results\n","status_predictions = status_pipeline.predict(X_status_test)\n","print(status_predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions on the test data\n","status_predictions = status_pipeline.predict(X_status_test)\n","\n","# Show the test data and corresponding predictions\n","stauts_test_results = pd.DataFrame({'X_test': X_status_test, 'Predicted_y': status_predictions, 'Actual_y': y_stauts_test})\n","print(stauts_test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Validate the model by checking the model's training and testing accuracy.\n","training_accuracy = status_pipeline.score(X_status_train, y_status_train)\n","testing_accuracy = status_pipeline.score(X_status_test, y_stauts_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the confusion matrix\n","confusion_mat = confusion_matrix(y_stauts_test, status_predictions)\n","\n","# Print the confusion matrix\n","print(\"Status Confusion Matrix:\")\n","print(confusion_mat)\n","\n","# Print a classification report\n","print(\"Status Classification Report:\")\n","print(classification_report(y_stauts_test, status_predictions))\n","\n","# Print the overall accuracy\n","accuracy = accuracy_score(y_stauts_test, status_predictions)\n","print(\"Overall Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Title: y_sentiment_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sentiment_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(stop_words=None)),\n","    ('classifier', LinearSVC())\n","])\n","\n","sentiment_pipeline.fit(X_sentiment_train, y_sentiment_train)\n","\n","# Print the results\n","sentiment_predictions = sentiment_pipeline.predict(X_sentiment_test)\n","print(sentiment_predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions on the test data\n","sentiment_predictions = sentiment_pipeline.predict(X_sentiment_test)\n","\n","# Show the test data and corresponding predictions\n","sentiment_test_results = pd.DataFrame({'X_test': X_sentiment_test, 'Predicted_y': sentiment_predictions, 'Actual_y': y_sentiment_test})\n","print(sentiment_test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Validate the model by checking the model's training and testing accuracy.\n","training_accuracy = sentiment_pipeline.score(X_sentiment_train, y_sentiment_train)\n","testing_accuracy = sentiment_pipeline.score(X_sentiment_test, y_sentiment_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the confusion matrix\n","confusion_mat = confusion_matrix(y_sentiment_test, sentiment_predictions)\n","\n","# Print the confusion matrix\n","print(\"Sentiment Confusion Matrix:\")\n","print(confusion_mat)\n","\n","# Print a classification report\n","print(\"Sentiment Classification Report:\")\n","print(classification_report(y_sentiment_test, sentiment_predictions))\n","\n","# Print the overall accuracy\n","accuracy = accuracy_score(y_sentiment_test, sentiment_predictions)\n","print(\"Overall Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"cSTS3GTx9haK"},"source":["## Open AI"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1721783559373,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"UN7r6Ge39haK"},"outputs":[],"source":["# Load environment variables.\n","load_dotenv()\n","\n","# Set the model name for our LLMs.\n","OPENAI_MODEL = \"gpt-3.5-turbo\"\n","\n","# Store the API key in a variable.\n","OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n","\n","print(type(OPENAI_API_KEY))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.5)\n","simple_prompt = ChatPromptTemplate.from_template(\"{query}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mental_health_chatbot(statement):\n","    format = \"\"\"\n","    You are a clinical psychologist. Answer only questions that would be relevant to mental health.\n","    If you don't know the answer, say you don't know\n","    If the human asks questions not related to mental health, remind them that your job is to help\n","    them understand their mental health status, and ask them for a question on that topic. If they ask a question which\n","    there is not enough information to answer, tell them you don't know and don't make up an\n","    answer.\n","\n","    Question: {query}\n","    Answer:\n","    \"\"\"\n","\n","\n","    #contstruct the prompt template\n","\n","    prompt_template = PromptTemplate(\n","        input_variables=[\"query\"],\n","        template=format\n","\n","    )\n","\n","    #contstuct a chain using this template\n","    chain = LLMChain(llm=llm, prompt=prompt_template) \n","    statement = statement\n","    status = status_pipeline.predict([statement])\n","    sentiment = sentiment_pipeline.predict([statement])\n","    query = {\"query\":f'The statement from the user is:{statement}\\n The mental health status of the user is/has:{status}\\n The sentiment of the statement is:{sentiment}\\n Does the user require any assistance? If so what would you suggest?'}\n","    #run the chain\n","\n","\n","    result = chain.invoke(query)\n","    return result[\"text\"]"]},{"cell_type":"markdown","metadata":{"id":"OQiYoYdO9haL"},"source":["## Gradio App"]},{"cell_type":"markdown","metadata":{"id":"ydFJqwsuAyRV"},"source":["This section of code involves a user interface where users input statements about their mental state. The code then processes these inputs and returns corresponding mental health statuses using two display textbox components. The purpose is to predict and provide insights into the user's mental state based on their statements.\n","\n","The data source consolidates information from various Kaggle datasets centered on different facets of mental health. It draws from diverse platforms such as social media, Reddit, Twitter, and more. Each entry is labeled with a specific mental health status, making it an invaluable resource for in-depth analyses, insights into mental health trends, patterns, and predictive modeling.\n","https://www.kaggle.com/datasets/suchintikasarkar/sentiment-analysis-for-mental-health"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14312,"status":"ok","timestamp":1721783573679,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"3yyZxFVv9haL","outputId":"73c9151f-2431-4ee2-fffb-c4ff09cdf86f"},"outputs":[],"source":["# Uncomment these lines if you are using Google Colab.\n","! pip install transformers\n","! pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20456,"status":"ok","timestamp":1721783594124,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"u7THB-ebAcZP"},"outputs":[],"source":["# Import transformers pipeline\n","from transformers import pipeline\n","# Import Gradio\n","import gradio as gr"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1721783594125,"user":{"displayName":"Kanish Mohan","userId":"03360479849440540993"},"user_tz":240},"id":"U4_ivXgmAjqo"},"outputs":[],"source":["# Initialize the pipeline to generate questions and answers using the distilbert-base-cased-distilled-squad model.\n","# question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms8qPG8bDoab"},"outputs":[],"source":["# !pip install --upgrade gradio\n","\n","import pandas as pd\n","import gradio as gr\n","\n","# Step 1: Load your CSV into a Pandas DataFrame\n","df = pd.read_csv('/Combined Data.csv')\n","\n","# Step 2: Define your Gradio interface and processing function\n","def predict_mental_health_status(statement):\n","    # Example: In a real application, this function would perform text classification or analysis\n","    # For simplicity, this example checks if the statement contains keywords\n","    if 'depression' in statement.lower():\n","        prediction = 'Depression'\n","    elif 'suicidal' in statement.lower():\n","        prediction = 'Suicidal'\n","    elif 'anxiety' in statement.lower():\n","        prediction = 'Anxiety'\n","    elif 'stress' in statement.lower():\n","        prediction = 'Stress'\n","    elif 'bi-polar' in statement.lower() or 'bipolar' in statement.lower():\n","        prediction = 'Bi-Polar'\n","    elif 'personality disorder' in statement.lower():\n","        prediction = 'Personality Disorder'\n","    else:\n","        prediction = 'Normal'\n","\n","    return prediction\n","\n","# Step 3: Define Gradio interface\n","app = gr.Interface(\n","    fn=predict_mental_health_status,\n","    inputs=gr.Textbox(label=\"Enter your statement\"), # Use gr.inputs.Textbox\n","    outputs=gr.Textbox(label=\"Predicted Mental Health Status\") # Use gr.outputs.Textbox\n",")\n","\n","# Step 4: Launch the Gradio app\n","app.launch(show_error=True)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"dev","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
